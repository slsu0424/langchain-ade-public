{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET OPENAI API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set API keys to authenticate requests to the API\n",
    "API_KEY = '<API Key>'\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text document\n",
    "loaders = TextLoader('<path to text document>')\n",
    "\n",
    "# create vector representation of the loaded document\n",
    "index = VectorstoreIndexCreator().from_loaders([loaders])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET UP STREAMLIT APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display page title and text box for the user to ask questions\n",
    "# to run streamlit, input into terminal: streamlit run the .py version of this file\n",
    "st.title('ðŸ¦œ LangChain: Chat with Adverse Events Report')\n",
    "prompt = st.text_input(\"Enter your question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATE RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the resonse from LLM\n",
    "if prompt:\n",
    "    response = index.query(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2), \n",
    "        question = prompt, \n",
    "        chain_type = 'stuff')\n",
    "\n",
    "    # write the results from the LLM to the UI\n",
    "    st.write(\"<b>\" + prompt + \"</b><br><i>\" + response + \"</i><hr>\", unsafe_allow_html=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONVERT TO .PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all ok, convert to .py notebook\n",
    "\n",
    "# bash\n",
    "# ! python3 -m nbconvert --to script langchain-ade.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
